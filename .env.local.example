# BrightForge Environment Configuration
# Copy this file to .env.local and fill in your API keys
# All API keys are optional - BrightForge works with Ollama (free, local) if no keys are set

# ============================================================
# LLM Provider API Keys (Free-First Chain)
# ============================================================

# Groq - Free tier with 14,000 tokens/min
# Get your key at: https://console.groq.com
GROQ_API_KEY=

# Cerebras - Free tier with ultra-fast inference
# Get your key at: https://cloud.cerebras.ai
CEREBRAS_API_KEY=

# Together AI - Free $25 credit + FLUX image generation
# Get your key at: https://api.together.xyz
TOGETHER_API_KEY=

# Mistral - Free tier with Mixtral models
# Get your key at: https://console.mistral.ai
MISTRAL_API_KEY=

# Google Gemini - Free tier + image generation (Nano Banana)
# Get your key at: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=

# Anthropic Claude - Paid fallback (high quality)
# Get your key at: https://console.anthropic.com
CLAUDE_API_KEY=

# OpenAI - Paid last resort (GPT-4)
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# OpenRouter - Aggregator with multiple providers
# Get your key at: https://openrouter.ai/keys
OPENROUTER_API_KEY=

# ============================================================
# Image Provider API Keys (Free-First Chain)
# ============================================================

# Pollinations - Completely free, no key required (FLUX model)
# No configuration needed!

# Stability AI - Premium fallback (disabled by default)
# Get your key at: https://platform.stability.ai
# STABILITY_API_KEY=

# ============================================================
# Server Configuration
# ============================================================

# Web server port (default: 3847)
PORT=3847

# Environment mode (development or production)
NODE_ENV=development

# Python inference server port (default: 8765)
PYTHON_PORT=8765

# ============================================================
# Optional: Custom Provider Endpoints
# ============================================================

# Ollama endpoint (default: http://127.0.0.1:11434)
# OLLAMA_HOST=http://127.0.0.1:11434

# Custom OpenAI-compatible endpoint
# OPENAI_BASE_URL=https://your-proxy.com/v1
